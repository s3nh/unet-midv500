{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "from models.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unet_best_2.pt',\n",
       " 'unet_best_3.pt',\n",
       " 'unet_best_1.pt',\n",
       " 'unet_best_4.pt',\n",
       " 'unet_best_0.pt',\n",
       " 'unet_best_5.pt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.load('trained_model/unet_best_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (dconv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (uconv3): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uconv2): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uconv1): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (lconv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(n_class = 1)\n",
    "model.load_state_dict(results['model_state_dict'])\n",
    "#model = nn.Sequential(model, nn.Sigmoid())\n",
    "#model.eval()\n",
    "#model.float();\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example images \n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "image = cv2.imread('data_processed/images/{}'.format(np.random.choice(os.listdir('data_processed/images'))))\n",
    "#image = transform(image)\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([albumentations.LongestMaxSize(max_size=768, p=1), \n",
    "                          albumentations.Normalize(p=1)], p=1)\n",
    "\n",
    "#image, pads = pad(image, factor=768)\n",
    "\n",
    "image = transform(image=image)[\"image\"]\n",
    "image = np.moveaxis(image, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = model(torch.from_numpy(image).unsqueeze(0).float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_image= output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations \n",
    "import cv2\n",
    "from src.dataset import MidvDataset\n",
    "from pathlib import Path \n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.optim import Adam \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = sorted(list(Path('data_processed/images').rglob('*.jpg')))\n",
    "list_masks = sorted(list(Path('data_processed/labels').rglob('*.png')))\n",
    "list_images = [str(el) for el in list_images]\n",
    "list_masks = [str(el) for el in list_masks]\n",
    "\n",
    "samples = list(zip(list_images, list_masks))\n",
    "samples = [tuple(el) for el in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MidvDataset(samples = samples, transform = albumentations.Compose( [albumentations.LongestMaxSize(max_size= 768 , p=1)], p=1  ))\n",
    "train_dt, test_dt = torch.utils.data.random_split(dataset,[ int(0.8* len(dataset)), int(0.2* len(dataset))])\n",
    "train_loader = DataLoader(train_dt,  batch_size = 4, shuffle = True, num_workers = 0)\n",
    "test_loader = DataLoader(test_dt, shuffle = True, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 5.93 GiB total capacity; 5.18 GiB already allocated; 11.50 MiB free; 5.45 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ecb28e7c7046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#mask = res['masks'].float().cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git-s3nh/smart-warehouse/models/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Encoder part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m#conv1 = self.dconv1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 5.93 GiB total capacity; 5.18 GiB already allocated; 11.50 MiB free; 5.45 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "out = model(res['features'].float().cuda() )\n",
    "#mask = res['masks'].float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_numpy = out.squeeze(0)[0][0].cpu().detach().numpy()\n",
    "#_mask = mask.squeeze(0)[0][0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff04fa09978>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((out_numpy > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ef48c3b41eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_mask' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = transform(image = example_image, mask = example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolbelt.utils.torch_utils import tensor_from_rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tensor_from_rgb_image(transformed['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (transformed['mask'] > 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([albumentations.LongestMaxSize(max_size=512, p=1), \n",
    "                          albumentations.Normalize(p=1)], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.from_numpy(mask).unsqueeze(0).numpy()[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for masks lack of information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "criterion = JaccardLoss(mode=\"binary\", from_logits=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, res in enumerate(train_loader, 0):\n",
    "        inputs = res['features'].float().cuda()\n",
    "        labels = res['masks'].long().cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
