{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19a54862c304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMidvDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongestMaxSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtrain_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dt\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "from models.unet import UNet\n",
    "from src.dataset import MidvDataset\n",
    "import torch.nn as nn \n",
    "import albumentations\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import typing\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from models.unet import UNet\n",
    "from src.dataset import MidvDataset\n",
    "from pathlib import Path \n",
    "from models.loss import dice_loss\n",
    "from torchsummary import summary \n",
    "from pytorch_toolbelt.losses import JaccardLoss, BinaryFocalLoss\n",
    "import os \n",
    "import time\n",
    "\n",
    "dataset = MidvDataset(samples = samples, transform = albumentations.Compose( [albumentations.LongestMaxSize(max_size=512 , p=1)], p=1  ))\n",
    "train_dt, test_dt = torch.utils.data.random_split(dataset,[ int(0.8* len(dataset)), int(0.2* len(dataset))])\n",
    "train_loader = DataLoader(train_dt,  batch_size = 4, shuffle = True, num_workers = 0)\n",
    "test_loader = DataLoader(test_dt, shuffle = True, batch_size = 4)\n",
    "#model = model.cuda()\n",
    "#criterion =  JaccardLoss(mode ='binary') \n",
    "#criterion = torch.nn.BCELoss().cuda()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, res in enumerate(train_loader, 0):\n",
    "        inputs = res['features'].float().cuda()\n",
    "        labels = res['masks'].float().cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = sorted(list(Path('data_processed/images').rglob('*.jpg')))\n",
    "list_masks = sorted(list(Path('data_processed/labels').rglob('*.png')))\n",
    "list_masks = [str(el) for el in list_masks]\n",
    "list_images = [str(el) for el in list_images]\n",
    "samples = list(zip(list_images, list_masks))\n",
    "samples = [tuple(el) for el in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data_processed/images/TS35_21.jpg', 'data_processed/labels/TS35_21.png'),\n",
       " ('data_processed/images/TS35_22.jpg', 'data_processed/labels/TS35_22.png'),\n",
       " ('data_processed/images/TS35_23.jpg', 'data_processed/labels/TS35_23.png'),\n",
       " ('data_processed/images/TS35_24.jpg', 'data_processed/labels/TS35_24.png'),\n",
       " ('data_processed/images/TS35_25.jpg', 'data_processed/labels/TS35_25.png'),\n",
       " ('data_processed/images/TS35_26.jpg', 'data_processed/labels/TS35_26.png'),\n",
       " ('data_processed/images/TS35_27.jpg', 'data_processed/labels/TS35_27.png'),\n",
       " ('data_processed/images/TS35_28.jpg', 'data_processed/labels/TS35_28.png'),\n",
       " ('data_processed/images/TS35_29.jpg', 'data_processed/labels/TS35_29.png'),\n",
       " ('data_processed/images/TS35_30.jpg', 'data_processed/labels/TS35_30.png')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
