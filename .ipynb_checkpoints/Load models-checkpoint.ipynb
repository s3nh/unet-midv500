{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "from models.unet import UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): UNet(\n",
       "    (dconv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (dconv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (uconv3): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (uconv2): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (uconv1): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (lconv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(n_class = 1)\n",
    "model.load_state_dict(torch.load('trained_model/unet_midv_adam_25.pt'))\n",
    "model = nn.Sequential(model, nn.Sigmoid())\n",
    "model.eval()\n",
    "model.float();\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example images \n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "image = cv2.imread('data_processed/images/{}'.format(np.random.choice(os.listdir('data_processed/images'))))\n",
    "#image = transform(image)\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([albumentations.LongestMaxSize(max_size=512, p=1), \n",
    "                          albumentations.Normalize(p=1)], p=1)\n",
    "\n",
    "#image, pads = pad(image, factor=768)\n",
    "\n",
    "image = transform(image=image)[\"image\"]\n",
    "image = np.moveaxis(image, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(torch.from_numpy(image).unsqueeze(0).float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_image= output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations \n",
    "import cv2\n",
    "from src.dataset import MidvDataset\n",
    "from pathlib import Path \n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.optim import Adam \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = list(Path('data_processed/images').rglob('*.jpg'))\n",
    "list_masks = list(Path('data_processed/labels').rglob('*.png'))\n",
    "list_images = [str(el) for el in list_images]\n",
    "list_masks = [str(el) for el in list_masks]\n",
    "\n",
    "samples = list(zip(list_images, list_masks))\n",
    "samples = [tuple(el) for el in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MidvDataset(samples = samples, transform = albumentations.Compose( [albumentations.LongestMaxSize(max_size=512 , p=1)], p=1  ))\n",
    "train_dt, test_dt = torch.utils.data.random_split(dataset,[ int(0.8* len(dataset)), int(0.2* len(dataset))])\n",
    "train_loader = DataLoader(train_dt,  batch_size = 4, shuffle = True, num_workers = 0)\n",
    "test_loader = DataLoader(test_dt, shuffle = True, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mask = cv2.imread(samples[1][1] , cv2.IMREAD_GRAYSCALE)\n",
    "example_image = cv2.imread(samples[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 43,  42,  40,  ...,  45,  43,  43],\n",
       "          [ 43,  40,  40,  ...,  46,  42,  41],\n",
       "          [ 40,  39,  40,  ...,  42,  42,  43],\n",
       "          ...,\n",
       "          [  2,   2,   2,  ..., 203, 201, 204],\n",
       "          [  2,   2,   2,  ..., 202, 205, 204],\n",
       "          [  2,   2,   2,  ..., 203, 203, 205]],\n",
       "\n",
       "         [[ 97,  97,  97,  ..., 110, 111, 111],\n",
       "          [ 98,  97,  97,  ..., 112, 112, 111],\n",
       "          [ 97,  96,  98,  ..., 110, 112, 113],\n",
       "          ...,\n",
       "          [  4,   4,   4,  ..., 203, 200, 203],\n",
       "          [  4,   4,   4,  ..., 203, 204, 203],\n",
       "          [  4,   4,   4,  ..., 205, 203, 205]],\n",
       "\n",
       "         [[168, 167, 166,  ..., 193, 194, 194],\n",
       "          [168, 166, 166,  ..., 195, 195, 194],\n",
       "          [166, 165, 164,  ..., 193, 195, 196],\n",
       "          ...,\n",
       "          [  4,   4,   5,  ..., 209, 202, 207],\n",
       "          [  4,   4,   5,  ..., 207, 206, 205],\n",
       "          [  4,   4,   5,  ..., 206, 203, 205]]],\n",
       "\n",
       "\n",
       "        [[[ 82,  75,  67,  ...,  68,  77,  81],\n",
       "          [ 82,  79,  62,  ...,  77,  82,  82],\n",
       "          [ 90,  77,  62,  ...,  80,  81,  81],\n",
       "          ...,\n",
       "          [ 51,  59,  60,  ...,  98, 110, 122],\n",
       "          [ 53,  58,  52,  ..., 113, 111, 115],\n",
       "          [ 49,  58,  54,  ..., 103, 103, 103]],\n",
       "\n",
       "         [[149, 142, 129,  ..., 125, 130, 134],\n",
       "          [149, 146, 126,  ..., 129, 134, 136],\n",
       "          [154, 141, 128,  ..., 131, 133, 134],\n",
       "          ...,\n",
       "          [101, 109, 109,  ..., 130, 142, 154],\n",
       "          [104, 106,  99,  ..., 145, 143, 147],\n",
       "          [102, 105, 101,  ..., 135, 135, 135]],\n",
       "\n",
       "         [[210, 205, 197,  ..., 194, 197, 200],\n",
       "          [210, 209, 194,  ..., 199, 204, 202],\n",
       "          [216, 206, 193,  ..., 201, 203, 201],\n",
       "          ...,\n",
       "          [159, 169, 171,  ..., 179, 191, 203],\n",
       "          [160, 167, 161,  ..., 194, 192, 196],\n",
       "          [157, 166, 163,  ..., 184, 184, 184]]],\n",
       "\n",
       "\n",
       "        [[[ 35,  25,  28,  ...,  24,  25,  26],\n",
       "          [ 32,  27,  31,  ...,  21,  25,  29],\n",
       "          [ 31,  33,  29,  ...,  24,  27,  27],\n",
       "          ...,\n",
       "          [ 26,  26,  26,  ...,  15,  15,  13],\n",
       "          [ 19,  21,  24,  ...,  17,  16,  16],\n",
       "          [ 25,  29,  29,  ...,  12,  14,  15]],\n",
       "\n",
       "         [[ 54,  50,  54,  ...,  40,  39,  41],\n",
       "          [ 55,  51,  57,  ...,  38,  42,  45],\n",
       "          [ 55,  57,  53,  ...,  43,  45,  45],\n",
       "          ...,\n",
       "          [ 49,  48,  49,  ...,  24,  26,  24],\n",
       "          [ 41,  43,  47,  ...,  25,  27,  27],\n",
       "          [ 49,  51,  51,  ...,  20,  24,  26]],\n",
       "\n",
       "         [[ 95,  91,  94,  ...,  72,  72,  73],\n",
       "          [ 96,  93,  99,  ...,  71,  75,  81],\n",
       "          [ 97,  99,  95,  ...,  78,  82,  83],\n",
       "          ...,\n",
       "          [ 82,  83,  81,  ...,  51,  53,  51],\n",
       "          [ 75,  79,  79,  ...,  54,  54,  54],\n",
       "          [ 82,  87,  87,  ...,  49,  52,  53]]],\n",
       "\n",
       "\n",
       "        [[[ 34,  35,  30,  ...,  42,  40,  40],\n",
       "          [ 35,  36,  34,  ...,  42,  42,  40],\n",
       "          [ 35,  35,  34,  ...,  46,  39,  34],\n",
       "          ...,\n",
       "          [ 39,  49,  52,  ...,  17,  20,  19],\n",
       "          [ 29,  33,  33,  ...,  16,  18,  19],\n",
       "          [ 41,  58,  38,  ...,  15,  18,  21]],\n",
       "\n",
       "         [[ 92,  97,  93,  ..., 102, 103, 104],\n",
       "          [ 93,  96,  93,  ...,  96, 102, 100],\n",
       "          [ 94,  93,  92,  ..., 100, 102,  96],\n",
       "          ...,\n",
       "          [ 90, 100, 103,  ...,  64,  65,  62],\n",
       "          [ 82,  86,  85,  ...,  61,  59,  58],\n",
       "          [ 92, 108,  88,  ...,  59,  58,  58]],\n",
       "\n",
       "         [[181, 185, 183,  ..., 184, 187, 186],\n",
       "          [181, 185, 182,  ..., 180, 184, 182],\n",
       "          [180, 182, 181,  ..., 183, 183, 180],\n",
       "          ...,\n",
       "          [170, 180, 183,  ..., 132, 133, 130],\n",
       "          [162, 166, 165,  ..., 129, 128, 126],\n",
       "          [172, 188, 169,  ..., 130, 127, 126]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 5.93 GiB total capacity; 4.86 GiB already allocated; 70.50 MiB free; 4.90 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c1a01495d909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git-s3nh/smart-warehouse/models/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3011\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3012\u001b[0m         return torch._C._nn.upsample_bilinear2d(input, _interp_output_size(2, closed_over_args), align_corners, \n\u001b[0;32m-> 3013\u001b[0;31m                                                 scale_factor_list[0], scale_factor_list[1])\n\u001b[0m\u001b[1;32m   3014\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trilinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3015\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got 4D input, but trilinear mode needs 5D input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 5.93 GiB total capacity; 4.86 GiB already allocated; 70.50 MiB free; 4.90 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "out = model(next(iter(train_loader))['features'].float().cuda() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_numpy = out.squeeze(0)[0][0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f75b58d2d30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((out_numpy).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-22-e4758d780bbd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-e4758d780bbd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [plt.imshow(example_image)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "[plt.imshow(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f75b59e3320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = transform(image = example_image, mask = example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolbelt.utils.torch_utils import tensor_from_rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tensor_from_rgb_image(transformed['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (transformed['mask'] > 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([albumentations.LongestMaxSize(max_size=512, p=1), \n",
    "                          albumentations.Normalize(p=1)], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.from_numpy(mask).unsqueeze(0).numpy()[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for masks lack of information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "criterion = JaccardLoss(mode=\"binary\", from_logits=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, res in enumerate(train_loader, 0):\n",
    "        inputs = res['features'].float().cuda()\n",
    "        labels = res['masks'].long().cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
